"""
==============================================
APP.PY - FLASK WEB APP V·ªöI ML MODEL M·ªöI
==============================================
T√≠ch h·ª£p m√¥ h√¨nh ML ƒë∆∞·ª£c train b·ªüi train.py
"""

from flask import Flask, render_template, request, flash, jsonify
import joblib
import json
import numpy as np
import pandas as pd
import os
import sys
import logging
from datetime import datetime

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o Flask app
app = Flask(__name__, template_folder='web/templates', static_folder='web/static')
app.config["SECRET_KEY"] = "movie-success-predictor-ml-2024"
app.config["VERSION"] = "3.0"  # TƒÉng version ƒë·ªÉ clear cache - Modern UI

# ==========================================
# LOAD M√î H√åNH ML M·ªöI
# ==========================================
try:
    models_dir = './models'
    
    # Th·ª≠ load best model (t·ª´ train.py)
    model_path = os.path.join(models_dir, 'best_model.pkl')
    
    if os.path.exists(model_path):
        # S·ª≠ d·ª•ng m√¥ h√¨nh m·ªõi
        model = joblib.load(model_path)
        logger.info("‚úÖ ƒê√£ load m√¥ h√¨nh M·ªöI (best_model.pkl)")
        
        # Load metadata
        metadata_path = model_path.replace('.pkl', '_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            logger.info(f"‚úÖ M√¥ h√¨nh: {metadata['model_name']}")
            logger.info(f"‚úÖ F1-Score: {metadata['test_metrics']['f1']:.4f}")
            logger.info(f"‚úÖ Best Threshold: {metadata['best_threshold']:.4f}")
            BEST_THRESHOLD = metadata['best_threshold']
            MODEL_NAME = metadata['model_name']
            MODEL_METRICS = metadata['test_metrics']
            USE_NEW_MODEL = True
        else:
            logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y metadata, s·ª≠ d·ª•ng threshold m·∫∑c ƒë·ªãnh")
            BEST_THRESHOLD = 0.5
            MODEL_NAME = "Best Model"
            MODEL_METRICS = {}
            USE_NEW_MODEL = True
    else:
        # Fallback: s·ª≠ d·ª•ng m√¥ h√¨nh c≈©
        logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y best_model.pkl, s·ª≠ d·ª•ng m√¥ h√¨nh C≈®")
        old_model_path = os.path.join(models_dir, 'movie_success_model.pkl')
        
        if not os.path.exists(old_model_path):
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i {old_model_path}")
            logger.info("üí° Vui l√≤ng ch·∫°y ./train.sh ƒë·ªÉ train m√¥ h√¨nh m·ªõi")
            logger.info("üí° Ho·∫∑c ƒë·∫£m b·∫£o c√≥ movie_success_model.pkl trong th∆∞ m·ª•c models/")
            sys.exit(1)
        
        model = joblib.load(old_model_path)
        logger.info("‚úÖ ƒê√£ load m√¥ h√¨nh C≈® (movie_success_model.pkl)")
        BEST_THRESHOLD = 0.5
        MODEL_NAME = "Legacy Model"
        MODEL_METRICS = {"note": "Train m√¥ h√¨nh m·ªõi ƒë·ªÉ c√≥ metrics chi ti·∫øt"}
        USE_NEW_MODEL = False

except Exception as e:
    logger.error(f"‚ùå L·ªói khi load model: {str(e)}")
    sys.exit(1)

# ==========================================
# FEATURE ENGINEERING (gi·ªëng train.py)
# ==========================================
def engineer_features(df):
    """
    Feature engineering gi·ªëng nh∆∞ trong train.py
    """
    df = df.copy()
    
    # 1. Date features
    if 'Release Date' in df.columns:
        df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')
        df['release_year'] = df['Release Date'].dt.year
        df['release_month'] = df['Release Date'].dt.month
        df['release_weekday'] = df['Release Date'].dt.weekday
        
        # Season
        def get_season(month):
            if pd.isna(month):
                return 0
            if month in [12, 1, 2]:
                return 1  # Winter
            elif month in [3, 4, 5]:
                return 2  # Spring
            elif month in [6, 7, 8]:
                return 3  # Summer
            else:
                return 4  # Fall
        
        df['release_season'] = df['release_month'].apply(get_season)
        df['is_holiday_release'] = df['release_month'].apply(
            lambda x: 1 if x in [6, 7, 8, 12, 1, 2] else 0 if pd.notna(x) else 0
        )
    
    # 2. ROI (n·∫øu c√≥ Revenue)
    if 'Budget' in df.columns and 'Revenue' in df.columns:
        df['ROI'] = df['Revenue'] / (df['Budget'] + 1)
    elif 'Budget' in df.columns:
        # N·∫øu kh√¥ng c√≥ Revenue, estimate ROI = 1.0 (break-even)
        df['ROI'] = 1.0
    
    # 3. Log transforms
    if 'Budget' in df.columns:
        df['budget_log'] = np.log1p(df['Budget'])
    
    if 'Revenue' in df.columns:
        df['revenue_log'] = np.log1p(df['Revenue'])
    
    if 'Vote Count' in df.columns:
        df['vote_count_log'] = np.log1p(df['Vote Count'])
    
    # 4. Interaction features
    if 'Budget' in df.columns and 'Vote Average' in df.columns:
        df['budget_vote_interaction'] = df['Budget'] * df['Vote Average']
    
    if 'Budget' in df.columns and 'Runtime' in df.columns:
        df['budget_per_minute'] = df['Budget'] / (df['Runtime'] + 1)
    
    if 'Vote Average' in df.columns and 'Vote Count' in df.columns:
        df['vote_score'] = df['Vote Average'] * np.log1p(df['Vote Count'])
    
    # 5. Missing value flags (set to 0 for prediction since we have values)
    for col in ['Budget', 'Revenue', 'Runtime', 'Vote Average']:
        col_name = col.lower().replace(" ", "_")
        if col in df.columns:
            df[f'is_missing_{col_name}'] = 0  # Set to 0 since we have values from form
        else:
            df[f'is_missing_{col_name}'] = 1  # Set to 1 if column doesn't exist
    
    return df

# ==========================================
# PREPARE INPUT DATA
# ==========================================
def prepare_input_data(form_data):
    """
    Chu·∫©n b·ªã input data t·ª´ form ƒë·ªÉ d·ª± ƒëo√°n
    """
    if USE_NEW_MODEL:
        # S·ª≠ d·ª•ng feature engineering cho m√¥ h√¨nh m·ªõi
        data = {
            # Required original columns
            'Id': 0,
            'Original Title': form_data.get('title', 'Unknown'),
            'Original Language': 'en',
            'Revenue': 0,  # Will be predicted
            'Budget': float(form_data.get('budget', 0)),
            'Runtime': float(form_data.get('runtime', 120)),
            'Vote Average': float(form_data.get('vote_average', 5)),
            'Vote Count': float(form_data.get('vote_count', 100)),
            'Release Date': f"{int(form_data.get('release_year', 2024))}-{int(form_data.get('release_month', 1)):02d}-15",
            
            # Categorical features
            'Genres': f"['{form_data.get('genre', 'Drama')}']",
            'Production Companies': '[]',
            'Production Countries': f"['{form_data.get('country', 'United States of America')}']",
            'Spoken Languages': "['English']",
            'Director': 'Unknown',
            'Stars': 'Unknown',
            
            # Will be calculated in engineer_features
            'ROI': 1.0  # Placeholder
        }
        
        # T·∫°o DataFrame
        df = pd.DataFrame([data])
        
        # Feature engineering
        df = engineer_features(df)
        
        return df
    else:
        # M√¥ h√¨nh c≈©: s·ª≠ d·ª•ng encoders v√† scaler c√≥ s·∫µn
        logger.info("S·ª≠ d·ª•ng preprocessing c≈©...")
        
        # Load encoders v√† scaler
        try:
            scaler = joblib.load('./models/feature_scaler.pkl')
            encoders = joblib.load('./models/encoders.pkl')
        except:
            logger.error("‚ùå Kh√¥ng t√¨m th·∫•y scaler ho·∫∑c encoders cho m√¥ h√¨nh c≈©")
            raise ValueError("Missing preprocessing files")
        
        # Prepare numeric features
        numeric_values = [
            float(form_data.get('budget', 0)),
            float(form_data.get('runtime', 120)),
            float(form_data.get('vote_average', 5)),
            float(form_data.get('vote_count', 100)),
            int(form_data.get('release_year', 2024)),
            int(form_data.get('release_month', 1)),
            0  # weekday placeholder
        ]
        
        # Scale numeric features
        numeric_scaled = scaler.transform([numeric_values])
        
        # Encode categorical
        genre_encoded = encoders['Main_Genre'].transform([form_data.get('genre', 'Drama')])[0]
        country_encoded = encoders['Main_Country'].transform([form_data.get('country', 'United States of America')])[0]
        
        # Combine
        features = np.array([numeric_scaled[0].tolist() + [genre_encoded, country_encoded]])
        
        return features

# ==========================================
# ROUTES
# ==========================================
@app.route("/")
def home():
    """Trang ch·ªß"""
    # L·∫•y danh s√°ch genres v√† countries t·ª´ model n·∫øu c√≥
    genres = [
        "Action", "Adventure", "Animation", "Comedy", "Crime",
        "Documentary", "Drama", "Family", "Fantasy", "History",
        "Horror", "Music", "Mystery", "Romance", "Science Fiction",
        "TV Movie", "Thriller", "War", "Western"
    ]
    
    countries = [
        "United States of America", "United Kingdom", "France",
        "Germany", "Japan", "Canada", "Italy", "Spain",
        "Australia", "South Korea", "China", "India"
    ]
    
    return render_template("index.html", 
                         genres=genres, 
                         countries=countries,
                         model_name=MODEL_NAME,
                         model_metrics=MODEL_METRICS)

@app.route("/predict", methods=["POST"])
def predict():
    """D·ª± ƒëo√°n th√†nh c√¥ng phim"""
    try:
        # L·∫•y d·ªØ li·ªáu t·ª´ form
        title = request.form.get("title", "").strip()
        
        # Validate
        if not title:
            flash("‚ö†Ô∏è Vui l√≤ng nh·∫≠p t√™n phim.", "error")
            return home()
        
        form_data = {
            'budget': request.form.get("budget", 0),
            'runtime': request.form.get("runtime", 120),
            'vote_average': request.form.get("director_rating", 5),
            'vote_count': request.form.get("actor_rating", 100),
            'release_year': request.form.get("release_year", 2024),
            'release_month': request.form.get("release_month", 1),
            'genre': request.form.get("genre", "Drama"),
            'country': request.form.get("country", "United States of America")
        }
        
        # Validate numeric inputs
        try:
            budget = float(form_data['budget'])
            runtime = float(form_data['runtime'])
            vote_average = float(form_data['vote_average'])
            vote_count = float(form_data['vote_count'])
            
            if budget <= 0 or runtime <= 0 or vote_count <= 0:
                flash("‚ö†Ô∏è Ng√¢n s√°ch, th·ªùi l∆∞·ª£ng v√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° ph·∫£i l·ªõn h∆°n 0.", "error")
                return home()
            
            if vote_average < 0 or vote_average > 10:
                flash("‚ö†Ô∏è ƒê√°nh gi√° trung b√¨nh ph·∫£i t·ª´ 0 ƒë·∫øn 10.", "error")
                return home()
                
        except ValueError:
            flash("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√°c gi√° tr·ªã s·ªë h·ª£p l·ªá.", "error")
            return home()
        
        # Chu·∫©n b·ªã input
        logger.info(f"D·ª± ƒëo√°n cho phim: {title}")
        input_data = prepare_input_data(form_data)
        
        # D·ª± ƒëo√°n
        if USE_NEW_MODEL:
            pred_proba = model.predict_proba(input_data)[:, 1][0]
        else:
            pred_proba = model.predict_proba(input_data)[0][1]
            
        prediction = 1 if pred_proba >= BEST_THRESHOLD else 0
        
        logger.info(f"Probability: {pred_proba:.4f}, Threshold: {BEST_THRESHOLD:.4f}, Prediction: {prediction}")
        
        # Debug: Check types before rendering
        logger.info(f"DEBUG - Types: budget={type(budget)}, runtime={type(runtime)}, vote_count={type(vote_count)}, release_year={type(form_data['release_year'])}")
        
        # K·∫øt qu·∫£
        if prediction == 1:
            result_text = "Th√†nh c√¥ng"
            result_class = "success"
            result_icon = "üéâ"
            confidence = pred_proba * 100
        else:
            result_text = "Kh√¥ng th√†nh c√¥ng"
            result_class = "failure"
            result_icon = "‚ö†Ô∏è"
            confidence = (1 - pred_proba) * 100
        
        # Convert all numpy types to Python native types for JSON serialization
        confidence_val = float(confidence)
        probability_val = float(pred_proba * 100)
        budget_val = float(budget)
        vote_average_val = float(vote_average)
        vote_count_val = int(vote_count)
        runtime_val = int(runtime)
        
        # Render k·∫øt qu·∫£
        return render_template("result.html",
                             title=title,
                             prediction=result_text,
                             confidence=round(confidence_val, 1),
                             probability=round(probability_val, 1),
                             color=result_class,
                             icon=result_icon,
                             budget=budget_val,
                             genre=form_data['genre'],
                             vote_average=vote_average_val,
                             vote_count=vote_count_val,
                             runtime=runtime_val,
                             release_year=int(form_data['release_year']),
                             release_month=int(form_data['release_month']),
                             country=form_data['country'],
                             model_name=MODEL_NAME,
                             threshold=round(BEST_THRESHOLD * 100, 1))
    
    except Exception as e:
        import traceback
        logger.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
        logger.error(f"Traceback:\n{traceback.format_exc()}")
        flash(f"‚ùå L·ªói: {str(e)}", "error")
        return home()

@app.route("/data")
def data_analysis():
    """Trang ph√¢n t√≠ch d·ªØ li·ªáu"""
    try:
        from src.data_analysis import create_data_visualizations
        visualizations, stats = create_data_visualizations()
        return render_template("data.html", **visualizations, stats=stats)
    except Exception as e:
        logger.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {str(e)}")
        flash(f"‚ö†Ô∏è L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {str(e)}", "error")
        return home()

@app.route("/api/predict", methods=["POST"])
def api_predict():
    """API endpoint cho d·ª± ƒëo√°n"""
    try:
        data = request.get_json()
        
        # Chu·∫©n b·ªã input
        input_df = prepare_input_data(data)
        
        # D·ª± ƒëo√°n
        pred_proba = model.predict_proba(input_df)[:, 1][0]
        prediction = 1 if pred_proba >= BEST_THRESHOLD else 0
        
        return jsonify({
            'success': True,
            'prediction': int(prediction),
            'prediction_label': 'Th√†nh c√¥ng' if prediction == 1 else 'Kh√¥ng th√†nh c√¥ng',
            'probability': float(pred_proba),
            'confidence': float(pred_proba if prediction == 1 else 1 - pred_proba),
            'threshold': float(BEST_THRESHOLD),
            'model_name': MODEL_NAME
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 400

@app.route("/model-info")
def model_info():
    """Th√¥ng tin m√¥ h√¨nh"""
    return jsonify({
        'model_name': MODEL_NAME,
        'threshold': float(BEST_THRESHOLD),
        'metrics': MODEL_METRICS,
        'status': 'active'
    })

@app.route("/css-test")
def css_test():
    """Trang test CSS"""
    return render_template('css_test.html')

@app.route("/api/ai-advice", methods=["POST"])
def ai_advice():
    """API endpoint ƒë·ªÉ l·∫•y l·ªùi khuy√™n t·ª´ Gemini AI"""
    try:
        import google.generativeai as genai
        
        # L·∫•y d·ªØ li·ªáu phim t·ª´ request
        data = request.get_json()
        
        # Configure Gemini API
        # S·ª≠ d·ª•ng API key t·ª´ environment ho·∫∑c config
        api_key = 'AIzaSyBJJE-2b49j7R8ugRgNVYC-N32QPSE8xN0'
        genai.configure(api_key=api_key)
        
        # T·∫°o model
        model = genai.GenerativeModel('gemini-2.5-flash')  # Ho·∫∑c 'gemini-pro'
        
        # T·∫°o prompt cho AI
        prompt = f"""
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch phim v√† t∆∞ v·∫•n s·∫£n xu·∫•t ƒëi·ªán ·∫£nh ‚Äî nh∆∞ng h√£y tr·∫£ l·ªùi **nh∆∞ ƒëang n√≥i chuy·ªán v·ªõi m·ªôt ng∆∞·ªùi b·∫°n**: th√¢n thi·ªán, tr·ª±c ti·∫øp, d·ªÖ hi·ªÉu v√† th·ª±c t·∫ø.

D·ª±a tr√™n k·∫øt qu·∫£ d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh Machine Learning, h√£y ph√¢n t√≠ch v√† t∆∞ v·∫•n cho b·ªô phim d∆∞·ªõi ƒë√¢y.

**Th√¥ng tin phim:**
- T√™n phim: {data.get('title')}
- D·ª± ƒëo√°n: {data.get('prediction')}
- ƒê·ªô tin c·∫≠y: {data.get('confidence')}%
- X√°c su·∫•t th√†nh c√¥ng: {data.get('probability')}%
- Ng√¢n s√°ch: ${data.get('budget'):,.0f}
- Th·ªÉ lo·∫°i: {data.get('genre')}
- ƒê√°nh gi√° trung b√¨nh: {data.get('vote_average')}/10
- S·ªë l∆∞·ª£ng ƒë√°nh gi√°: {data.get('vote_count'):,}
- Th·ªùi l∆∞·ª£ng: {data.get('runtime')} ph√∫t
- NƒÉm ph√°t h√†nh: {data.get('release_year')}
- Th√°ng ph√°t h√†nh: {data.get('release_month')}
- Qu·ªëc gia: {data.get('country')}

H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, d√πng **markdown** v·ªõi heading `###`, bullet `-`, v√† nh·∫•n m·∫°nh b·∫±ng `**text**`. Gi·ªØ gi·ªçng **chuy√™n gia nh∆∞ng g·∫ßn g≈©i**, v√† t·∫≠p trung v√†o khuy·∫øn ngh·ªã c√≥ th·ªÉ th·ª±c thi ƒë∆∞·ª£c.

Y√™u c·∫ßu ph·∫ßn ph√¢n t√≠ch:

### 1. **ƒê√°nh gi√° t·ªïng quan**
- N√≥i ng·∫Øn g·ªçn (2‚Äì4 c√¢u) v·ªÅ kh·∫£ nƒÉng th√†nh c√¥ng d·ª±a tr√™n c√°c ch·ªâ s·ªë ch√≠nh (probability, confidence, rating, budget, v.v).
- N·∫øu c·∫ßn, cho bi·∫øt m·ª©c r·ªßi ro t·ªïng th·ªÉ: **Th·∫•p / Trung b√¨nh / Cao**.

### 2. **ƒêi·ªÉm m·∫°nh**
- Li·ªát k√™ 3‚Äì5 y·∫øu t·ªë t√≠ch c·ª±c n·ªïi b·∫≠t (v√≠ d·ª•: ƒë·ªÅ t√†i, ƒë·ªô nh·∫≠n di·ªán, ƒëi·ªÉm ƒë√°nh gi√°, y·∫øu t·ªë th∆∞∆°ng m·∫°i).
- M·ªói bullet k√®m 1 c√¢u gi·∫£i th√≠ch ng·∫Øn.

### 3. **ƒêi·ªÉm y·∫øu / R·ªßi ro**
- Li·ªát k√™ 3‚Äì5 v·∫•n ƒë·ªÅ c·∫ßn l∆∞u √Ω (v√≠ d·ª•: ng√¢n s√°ch kh√¥ng t∆∞∆°ng x·ª©ng, target k√©m r√µ, c·∫°nh tranh th√°ng chi·∫øu).
- V·ªõi m·ªói r·ªßi ro, ƒë·ªÅ xu·∫•t 1 c√°ch gi·∫£m thi·ªÉu c·ª• th·ªÉ.

### 4. **L·ªùi khuy√™n c·ª• th·ªÉ (3‚Äì5 ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông)**
- Chia l√†m 4 nh√≥m nh·ªè: **Marketing & ph√°t h√†nh**, **Ng√¢n s√°ch & ƒë·∫ßu t∆∞**, **Th·ªùi ƒëi·ªÉm & th·ªã tr∆∞·ªùng m·ª•c ti√™u**, **C·∫£i thi·ªán n·ªôi dung**.
- V·ªõi m·ªói nh√≥m, ƒë∆∞a 1‚Äì2 khuy·∫øn ngh·ªã r√µ r√†ng, c√≥ th·ªÉ ƒëo l∆∞·ªùng (v√≠ d·ª•: thay ƒë·ªïi ng√†y ra r·∫°p sang Q4, gi·∫£m 15% chi ph√≠ non-production, t·∫≠p trung PR v√†o c·ªông ƒë·ªìng X).
- N·∫øu h·ª£p l√Ω, ƒë·ªÅ xu·∫•t KPI ƒë∆°n gi·∫£n ƒë·ªÉ theo d√µi (v√≠ d·ª•: target CTR qu·∫£ng c√°o, s·ªë v√© m·ª•c ti√™u tu·∫ßn ƒë·∫ßu).

### 5. **So s√°nh th·ªã tr∆∞·ªùng & xu h∆∞·ªõng**
- N√™u 2‚Äì3 phim t∆∞∆°ng t·ª± (t√™n + l√Ω do t∆∞∆°ng ƒë·ªìng) v√† r√∫t ra b√†i h·ªçc th·ª±c t·∫ø t·ª´ ch√∫ng.
- K·∫øt lu·∫≠n ng·∫Øn v·ªÅ xu h∆∞·ªõng th·ªã tr∆∞·ªùng hi·ªán t·∫°i ·∫£nh h∆∞·ªüng t·ªõi phim n√†y (v√≠ d·ª•: demand cho phim indie, th·ªã tr∆∞·ªùng streaming, m√πa l·ªÖ h·ªôi).

### 6. **K·∫øt lu·∫≠n ng·∫Øn & b∆∞·ªõc ti·∫øp theo**
- K·∫øt th√∫c b·∫±ng 1‚Äì2 c√¢u t√≥m t·∫Øt: c√≥ n√™n ƒë·∫ßu t∆∞/ƒëi ti·∫øp kh√¥ng, v√† ∆∞u ti√™n h√†nh ƒë·ªông ti·∫øp theo l√† g√¨.
- (Th√¢n m·∫≠t) H·ªèi m·ªôt c√¢u m·ªü ƒë·ªÉ ti·∫øp: **"B·∫°n mu·ªën m√¨nh b√≥c t√°ch s√¢u v√†o ph·∫ßn marketing, ng√¢n s√°ch hay k·ªãch b·∫£n?"**

L∆∞u √Ω: ∆∞u ti√™n **th·ª±c ti·ªÖn** h∆°n l√† thu·∫≠t ng·ªØ h·ªçc thu·∫≠t ‚Äî h√£y tr√¨nh b√†y sao cho nh√† s·∫£n xu·∫•t/ƒë·ªôi marketing d·ªÖ hi·ªÉu v√† c√≥ th·ªÉ h√†nh ƒë·ªông ngay.
"""

        
        # G·ªçi API Gemini
        response = model.generate_content(prompt)
        
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£
        return jsonify({
            'success': True,
            'advice': response.text
        })
        
    except ImportError:
        logger.error("google-generativeai package not installed")
        return jsonify({
            'success': False,
            'error': 'AI service not configured. Please install google-generativeai package.'
        }), 500
        
    except Exception as e:
        logger.error(f"Error calling Gemini API: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Failed to get AI advice: {str(e)}'
        }), 500

# ==========================================
# ERROR HANDLERS
# ==========================================
@app.errorhandler(404)
def not_found(error):
    return render_template('index.html'), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal error: {error}")
    return render_template('index.html'), 500

# ==========================================
# MAIN
# ==========================================
if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("üé¨ MOVIE SUCCESS PREDICTOR - ML WEB APP")
    logger.info("=" * 60)
    logger.info(f"üìä Model: {MODEL_NAME}")
    logger.info(f"üéØ F1-Score: {MODEL_METRICS.get('f1', 'N/A')}")
    logger.info(f"‚öñÔ∏è Threshold: {BEST_THRESHOLD:.4f}")
    logger.info("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=5000)
