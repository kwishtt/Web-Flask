"""
==============================================
APP.PY - FLASK WEB APP V·ªöI ML MODEL M·ªöI
==============================================
T√≠ch h·ª£p m√¥ h√¨nh ML ƒë∆∞·ª£c train b·ªüi train.py
"""

from flask import Flask, render_template, request, flash, jsonify
import joblib
import json
import numpy as np
import pandas as pd
import os
import sys
import logging
from datetime import datetime

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o Flask app
app = Flask(__name__, template_folder='web/templates', static_folder='web/static')
app.config["SECRET_KEY"] = "movie-success-predictor-ml-2024"
app.config["VERSION"] = "3.0"  # TƒÉng version ƒë·ªÉ clear cache - Modern UI

# ==========================================
# LOAD M√î H√åNH ML M·ªöI
# ==========================================
try:
    models_dir = './models'
    
    # Th·ª≠ load best model (t·ª´ train.py)
    model_path = os.path.join(models_dir, 'best_model.pkl')
    
    if os.path.exists(model_path):
        # S·ª≠ d·ª•ng m√¥ h√¨nh m·ªõi
        model = joblib.load(model_path)
        logger.info("‚úÖ ƒê√£ load m√¥ h√¨nh M·ªöI (best_model.pkl)")
        
        # Load metadata
        metadata_path = model_path.replace('.pkl', '_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            logger.info(f"‚úÖ M√¥ h√¨nh: {metadata['model_name']}")
            logger.info(f"‚úÖ F1-Score: {metadata['test_metrics']['f1']:.4f}")
            logger.info(f"‚úÖ Best Threshold: {metadata['best_threshold']:.4f}")
            BEST_THRESHOLD = metadata['best_threshold']
            MODEL_NAME = metadata['model_name']
            MODEL_METRICS = metadata['test_metrics']
            USE_NEW_MODEL = True
        else:
            logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y metadata, s·ª≠ d·ª•ng threshold m·∫∑c ƒë·ªãnh")
            BEST_THRESHOLD = 0.5
            MODEL_NAME = "Best Model"
            MODEL_METRICS = {}
            USE_NEW_MODEL = True
    else:
        # Fallback: s·ª≠ d·ª•ng m√¥ h√¨nh c≈©
        logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y best_model.pkl, s·ª≠ d·ª•ng m√¥ h√¨nh C≈®")
        old_model_path = os.path.join(models_dir, 'movie_success_model.pkl')
        
        if not os.path.exists(old_model_path):
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i {old_model_path}")
            logger.info("üí° Vui l√≤ng ch·∫°y ./train.sh ƒë·ªÉ train m√¥ h√¨nh m·ªõi")
            logger.info("üí° Ho·∫∑c ƒë·∫£m b·∫£o c√≥ movie_success_model.pkl trong th∆∞ m·ª•c models/")
            sys.exit(1)
        
        model = joblib.load(old_model_path)
        logger.info("‚úÖ ƒê√£ load m√¥ h√¨nh C≈® (movie_success_model.pkl)")
        BEST_THRESHOLD = 0.5
        MODEL_NAME = "Legacy Model"
        MODEL_METRICS = {"note": "Train m√¥ h√¨nh m·ªõi ƒë·ªÉ c√≥ metrics chi ti·∫øt"}
        USE_NEW_MODEL = False

except Exception as e:
    logger.error(f"‚ùå L·ªói khi load model: {str(e)}")
    sys.exit(1)

# ==========================================
# FEATURE ENGINEERING (gi·ªëng train.py)
# ==========================================
def engineer_features(df):
    """
    Feature engineering gi·ªëng nh∆∞ trong train.py
    """
    df = df.copy()
    
    # 1. Date features
    if 'Release Date' in df.columns:
        df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')
        df['release_year'] = df['Release Date'].dt.year
        df['release_month'] = df['Release Date'].dt.month
        df['release_weekday'] = df['Release Date'].dt.weekday
        
        # Season
        def get_season(month):
            if pd.isna(month):
                return 0
            if month in [12, 1, 2]:
                return 1  # Winter
            elif month in [3, 4, 5]:
                return 2  # Spring
            elif month in [6, 7, 8]:
                return 3  # Summer
            else:
                return 4  # Fall
        
        df['release_season'] = df['release_month'].apply(get_season)
        df['is_holiday_release'] = df['release_month'].apply(
            lambda x: 1 if x in [6, 7, 8, 12, 1, 2] else 0 if pd.notna(x) else 0
        )
    
    # 2. ROI (n·∫øu c√≥ Revenue)
    if 'Budget' in df.columns and 'Revenue' in df.columns:
        # If Revenue is 0 (prediction case), estimate reasonable Revenue
        if df['Revenue'].iloc[0] == 0 and 'Vote Average' in df.columns and 'Vote Count' in df.columns:
            # Estimate Revenue based on Budget, Vote Average, and Vote Count
            budget = df['Budget'].iloc[0]
            vote_avg = df['Vote Average'].iloc[0]
            vote_count = df['Vote Count'].iloc[0]
            
            # Base multiplier from budget (larger budgets tend to have higher ROI potential)
            budget_multiplier = 1.5 + (min(budget / 100_000_000, 2.0) * 0.5)  # 1.5x to 2.5x
            
            # Quality multiplier from ratings (higher ratings = higher revenue)
            quality_multiplier = max(0.5, min(vote_avg / 10.0, 1.0))  # 0.5x to 1.0x
            
            # Popularity multiplier from vote count (more votes = more awareness)
            popularity_multiplier = 1.0 + min(np.log1p(vote_count) / 15.0, 1.0)  # 1.0x to 2.0x
            
            # Estimate Revenue = Budget * combined multipliers
            estimated_revenue = budget * budget_multiplier * quality_multiplier * popularity_multiplier
            df['Revenue'] = estimated_revenue
            logger.info(f"Estimated Revenue: ${estimated_revenue:,.0f} (Budget: ${budget:,.0f}, Multipliers: {budget_multiplier:.2f}x{quality_multiplier:.2f}x{popularity_multiplier:.2f})")
        
        df['ROI'] = df['Revenue'] / (df['Budget'] + 1)
    elif 'Budget' in df.columns:
        # Fallback: estimate ROI based on Vote Average (higher rating = higher ROI)
        if 'Vote Average' in df.columns:
            vote_avg = df['Vote Average'].iloc[0]
            # ROI ranges from 0.8 (poor) to 3.0 (excellent)
            estimated_roi = 0.8 + (max(0, vote_avg - 5.0) / 5.0) * 2.2  # 5.0 vote = 0.8 ROI, 10.0 vote = 3.0 ROI
            df['ROI'] = estimated_roi
            logger.info(f"Estimated ROI: {estimated_roi:.2f} based on Vote Average: {vote_avg}")
        else:
            df['ROI'] = 1.5  # Default to moderate success
    
    # 3. Log transforms
    if 'Budget' in df.columns:
        df['budget_log'] = np.log1p(df['Budget'])
    
    if 'Revenue' in df.columns:
        df['revenue_log'] = np.log1p(df['Revenue'])
    
    if 'Vote Count' in df.columns:
        df['vote_count_log'] = np.log1p(df['Vote Count'])
    
    # 4. Interaction features
    if 'Budget' in df.columns and 'Vote Average' in df.columns:
        df['budget_vote_interaction'] = df['Budget'] * df['Vote Average']
    
    if 'Budget' in df.columns and 'Runtime' in df.columns:
        df['budget_per_minute'] = df['Budget'] / (df['Runtime'] + 1)
    
    if 'Vote Average' in df.columns and 'Vote Count' in df.columns:
        df['vote_score'] = df['Vote Average'] * np.log1p(df['Vote Count'])
    
    # 5. Missing value flags (set to 0 for prediction since we have values)
    for col in ['Budget', 'Revenue', 'Runtime', 'Vote Average']:
        col_name = col.lower().replace(" ", "_")
        if col in df.columns:
            df[f'is_missing_{col_name}'] = 0  # Set to 0 since we have values from form
        else:
            df[f'is_missing_{col_name}'] = 1  # Set to 1 if column doesn't exist
    
    # 6. Add missing engineered features that might be expected by model
    if 'is_holiday_release' not in df.columns:
        # Holiday release flag already added in date features section above
        pass  # Already handled
    
    # Ensure all numeric columns are float type for model compatibility
    numeric_cols = ['Budget', 'Revenue', 'Runtime', 'Vote Average', 'Vote Count', 'ROI', 
                   'release_year', 'release_month', 'release_weekday', 'release_season',
                   'vote_count_log', 'budget_vote_interaction', 'budget_per_minute']
    
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    return df

# ==========================================
# PREPARE INPUT DATA
# ==========================================
def prepare_input_data(form_data):
    """
    Chu·∫©n b·ªã input data t·ª´ form ƒë·ªÉ d·ª± ƒëo√°n - FIXED ƒë·ªÉ match training format
    """
    if USE_NEW_MODEL:
        # S·ª≠ d·ª•ng feature engineering cho m√¥ h√¨nh m·ªõi - EXACTLY 27 features
        data = {
            # Original columns (some unused by model but needed for completeness)
            'Id': 0,
            'Original Title': form_data.get('title', 'Unknown'),
            'Original Language': 'en',
            
        # CORE FEATURES that model actually uses
        'Revenue': 0,  # Will be estimated in engineer_features
        'Budget': float(form_data.get('budget', 0)),
        'Runtime': float(form_data.get('runtime', 120)),
        'Vote Average': float(form_data.get('vote_average', 5)),
        'Vote Count': float(form_data.get('vote_count', 100)),
        'Release Date': f"{int(form_data.get('release_year', 2024))}-{int(form_data.get('release_month', 1)):02d}-15",
        
        # CATEGORICAL FEATURES - exactly as model expects
        'Genres': f"['{form_data.get('genre', 'Drama')}']",  # Not used by model but keep for completeness
        'Production Companies': '[]',  # Not used by model
        'Production Countries': 'United States of America',  # Default value - not critical for prediction
        'Spoken Languages': 'English',  # Default value - not critical for prediction
        'Director': 'Unknown',  # Not used by model
        'Stars': 'Unknown',  # Not used by model            # ROI will be calculated in engineer_features
            'ROI': 1.0  # Placeholder
        }
        
        # T·∫°o DataFrame
        df = pd.DataFrame([data])
        
        # Feature engineering - this will add all needed engineered features
        df = engineer_features(df)
        
        # Debug: Check which columns are actually needed
        expected_features = [
            'Id', 'Original Title', 'Original Language', 'Revenue', 'Budget', 'Runtime', 
            'Vote Average', 'Vote Count', 'Genres', 'Production Companies', 'Production Countries', 
            'Spoken Languages', 'Director', 'Stars', 'ROI', 'release_year', 'release_month', 
            'release_weekday', 'release_season', 'is_holiday_release', 'vote_count_log', 
            'budget_vote_interaction', 'budget_per_minute', 'is_missing_budget', 
            'is_missing_revenue', 'is_missing_runtime', 'is_missing_vote_average'
        ]
        
        # Ensure all expected features exist
        for feat in expected_features:
            if feat not in df.columns:
                if 'is_missing_' in feat:
                    df[feat] = 0  # Set missing flags to 0 since we have the data
                else:
                    df[feat] = 0  # Default value for missing engineered features
                    logger.warning(f"Missing feature {feat}, setting to 0")
        
        # Select only the expected features in correct order
        df_final = df[expected_features]
        
        logger.info(f"Final input shape: {df_final.shape}")
        logger.info(f"Features generated: {df_final.columns.tolist()}")
        
        return df_final
    else:
        # M√¥ h√¨nh c≈©: s·ª≠ d·ª•ng encoders v√† scaler c√≥ s·∫µn
        logger.info("S·ª≠ d·ª•ng preprocessing c≈©...")
        
        # Load encoders v√† scaler
        try:
            scaler = joblib.load('./models/feature_scaler.pkl')
            encoders = joblib.load('./models/encoders.pkl')
        except:
            logger.error("‚ùå Kh√¥ng t√¨m th·∫•y scaler ho·∫∑c encoders cho m√¥ h√¨nh c≈©")
            raise ValueError("Missing preprocessing files")
        
        # Prepare numeric features
        numeric_values = [
            float(form_data.get('budget', 0)),
            float(form_data.get('runtime', 120)),
            float(form_data.get('vote_average', 5)),
            float(form_data.get('vote_count', 100)),
            int(form_data.get('release_year', 2024)),
            int(form_data.get('release_month', 1)),
            0  # weekday placeholder
        ]
        
        # Scale numeric features
        numeric_scaled = scaler.transform([numeric_values])
        
        # Encode categorical
        genre_encoded = encoders['Main_Genre'].transform([form_data.get('genre', 'Drama')])[0]
        country_encoded = encoders['Main_Country'].transform([form_data.get('country', 'United States of America')])[0]
        
        # Combine
        features = np.array([numeric_scaled[0].tolist() + [genre_encoded, country_encoded]])
        
        return features

# ==========================================
# ROUTES
# ==========================================
@app.route("/")
def home():
    """Trang ch·ªß"""
    # L·∫•y danh s√°ch genres t·ª´ model
    genres = [
        "Action", "Adventure", "Animation", "Comedy", "Crime",
        "Documentary", "Drama", "Family", "Fantasy", "History",
        "Horror", "Music", "Mystery", "Romance", "Science Fiction",
        "TV Movie", "Thriller", "War", "Western"
    ]
    
    # ƒê·∫ßy ƒë·ªß danh s√°ch countries v·ªõi autocomplete
    countries = [
        "Afghanistan", "Albania", "Algeria", "Argentina", "Australia", "Austria", "Bangladesh", "Belgium", 
        "Bolivia", "Brazil", "Bulgaria", "Canada", "Chile", "China", "Colombia", "Croatia", "Czech Republic", 
        "Denmark", "Ecuador", "Egypt", "Finland", "France", "Germany", "Greece", "Hong Kong", "Hungary", 
        "Iceland", "India", "Indonesia", "Iran", "Iraq", "Ireland", "Israel", "Italy", "Japan", "Jordan", 
        "Kazakhstan", "Kenya", "South Korea", "Kuwait", "Lebanon", "Libya", "Malaysia", "Mexico", "Morocco", 
        "Netherlands", "New Zealand", "Norway", "Pakistan", "Paraguay", "Peru", "Philippines", "Poland", 
        "Portugal", "Qatar", "Romania", "Russia", "Saudi Arabia", "Serbia", "Singapore", "Slovenia", 
        "South Africa", "Spain", "Sweden", "Switzerland", "Taiwan", "Thailand", "Tunisia", "Turkey", 
        "Ukraine", "United Arab Emirates", "United Kingdom", "United States of America", "Uruguay", "Venezuela", "Vietnam"
    ]
    
    return render_template("index.html", 
                         genres=genres, 
                         countries=countries,
                         model_name=MODEL_NAME,
                         model_metrics=MODEL_METRICS)

@app.route("/predict", methods=["POST"])
def predict():
    """D·ª± ƒëo√°n th√†nh c√¥ng phim"""
    try:
        # L·∫•y d·ªØ li·ªáu t·ª´ form
        title = request.form.get("title", "").strip()
        
        # Validate
        if not title:
            flash("‚ö†Ô∏è Vui l√≤ng nh·∫≠p t√™n phim.", "error")
            return home()
        
        form_data = {
            'budget': request.form.get("budget", 0),
            'runtime': request.form.get("runtime", 120),
            'vote_average': request.form.get("director_rating", 5),
            'vote_count': request.form.get("actor_rating", 100),
            'release_year': request.form.get("release_year", 2024),
            'release_month': request.form.get("release_month", 1),
            'genre': request.form.get("genre", "Drama")
            # Removed country field - not essential for prediction
        }
        
        # Validate numeric inputs
        try:
            budget = float(form_data['budget'])
            runtime = float(form_data['runtime'])
            vote_average = float(form_data['vote_average'])
            vote_count = float(form_data['vote_count'])
            
            if budget <= 0 or runtime <= 0 or vote_count <= 0:
                flash("‚ö†Ô∏è Ng√¢n s√°ch, th·ªùi l∆∞·ª£ng v√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° ph·∫£i l·ªõn h∆°n 0.", "error")
                return home()
            
            if vote_average < 0 or vote_average > 10:
                flash("‚ö†Ô∏è ƒê√°nh gi√° trung b√¨nh ph·∫£i t·ª´ 0 ƒë·∫øn 10.", "error")
                return home()
                
        except ValueError:
            flash("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√°c gi√° tr·ªã s·ªë h·ª£p l·ªá.", "error")
            return home()
        
        # Chu·∫©n b·ªã input
        logger.info(f"D·ª± ƒëo√°n cho phim: {title}")
        input_data = prepare_input_data(form_data)
        
        # Debug: Log input features
        logger.info(f"Input shape: {input_data.shape}")
        logger.info(f"Input columns: {input_data.columns.tolist()}")
        logger.info(f"Sample values: Budget={budget}, Runtime={runtime}, Vote_Avg={vote_average}")
        
        # D·ª± ƒëo√°n
        if USE_NEW_MODEL:
            pred_proba = model.predict_proba(input_data)[:, 1][0]
        else:
            pred_proba = model.predict_proba(input_data)[0][1]
            
        prediction = 1 if pred_proba >= BEST_THRESHOLD else 0
        
        logger.info(f"Probability: {pred_proba:.4f}, Threshold: {BEST_THRESHOLD:.4f}, Prediction: {prediction}")
        logger.info(f"Prediction result: {'SUCCESS' if prediction == 1 else 'FAILURE'}")
        
        # Debug: Check types before rendering
        logger.info(f"DEBUG - Types: budget={type(budget)}, runtime={type(runtime)}, vote_count={type(vote_count)}, release_year={type(form_data['release_year'])}")
        
        # K·∫øt qu·∫£
        if prediction == 1:
            result_text = "Th√†nh c√¥ng"
            result_class = "success"
            result_icon = "üéâ"
            confidence = pred_proba * 100
        else:
            result_text = "Kh√¥ng th√†nh c√¥ng"
            result_class = "failure"
            result_icon = "‚ö†Ô∏è"
            confidence = (1 - pred_proba) * 100
        
        # Convert all numpy types to Python native types for JSON serialization
        confidence_val = float(confidence)
        probability_val = float(pred_proba * 100)
        budget_val = float(budget)
        vote_average_val = float(vote_average)
        vote_count_val = int(vote_count)
        runtime_val = int(runtime)
        
        # Render k·∫øt qu·∫£
        return render_template("result.html",
                             title=title,
                             prediction=result_text,
                             confidence=round(confidence_val, 1),
                             probability=round(probability_val, 1),
                             color=result_class,
                             icon=result_icon,
                             budget=budget_val,
                             genre=form_data['genre'],
                             vote_average=vote_average_val,
                             vote_count=vote_count_val,
                             runtime=runtime_val,
                             release_year=int(form_data['release_year']),
                             release_month=int(form_data['release_month']),
                             # Removed country field
                             model_name=MODEL_NAME,
                             threshold=round(BEST_THRESHOLD * 100, 1))
    
    except Exception as e:
        import traceback
        logger.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
        logger.error(f"Traceback:\n{traceback.format_exc()}")
        flash(f"‚ùå L·ªói: {str(e)}", "error")
        return home()

@app.route("/data")
def data_analysis():
    """Trang ph√¢n t√≠ch d·ªØ li·ªáu - OPTIMIZED v·ªõi static images"""
    try:
        # T√≠nh stats nhanh t·ª´ dataset
        df = pd.read_csv('./data/Movies.csv')
        
        # Filter valid data
        df_valid = df.dropna(subset=['Budget', 'Revenue', 'Vote Average'])
        
        # Calculate stats
        stats = {
            'total_movies': len(df_valid),
            'total_raw_movies': len(df),
            'removed_movies': len(df) - len(df_valid),
            'removal_percentage': (len(df) - len(df_valid)) / len(df) * 100,
            'avg_budget': df_valid['Budget'].mean(),
            'avg_revenue': df_valid['Revenue'].mean(),
            'avg_vote': df_valid['Vote Average'].mean(),
            'avg_roi': (df_valid['Revenue'] / df_valid['Budget']).mean(),
            'genres_count': len(df_valid['Genres'].str.split(',').explode().unique()) if 'Genres' in df_valid.columns else 0,
            'year_range': f"{int(df_valid['Release Date'].str[:4].min())}-{int(df_valid['Release Date'].str[:4].max())}" if 'Release Date' in df_valid.columns else "N/A",
            'movies_with_profit': len(df_valid[df_valid['Revenue'] > df_valid['Budget']]),
            'movies_with_loss': len(df_valid[df_valid['Revenue'] <= df_valid['Budget']])
        }
        
        # Calculate success rate
        df_valid['ROI'] = df_valid['Revenue'] / df_valid['Budget']
        df_valid['Success'] = ((df_valid['ROI'] >= 1.0) & (df_valid['Vote Average'] >= 6.5)).astype(int)
        stats['success_rate'] = df_valid['Success'].mean() * 100
        
        # Add sample data (10 rows) for display
        sample_columns = ['Original Title', 'Genres', 'Budget', 'Revenue', 'Vote Average', 'Vote Count', 'Runtime', 'Release Date']
        df_sample = df_valid[sample_columns].head(10)
        
        # Convert to list of dicts for template
        stats['sample_data'] = df_sample.to_dict('records')
        stats['sample_columns'] = sample_columns
        
        # Render v·ªõi stats only - charts t·ª´ static images
        return render_template("data.html", stats=stats)
        
    except Exception as e:
        logger.error(f"L·ªói khi load d·ªØ li·ªáu: {str(e)}")
        flash(f"‚ö†Ô∏è L·ªói khi load d·ªØ li·ªáu: {str(e)}", "error")
        return home()

@app.route("/api/predict", methods=["POST"])
def api_predict():
    """API endpoint cho d·ª± ƒëo√°n"""
    try:
        data = request.get_json()
        
        # Chu·∫©n b·ªã input
        input_df = prepare_input_data(data)
        
        # D·ª± ƒëo√°n
        pred_proba = model.predict_proba(input_df)[:, 1][0]
        prediction = 1 if pred_proba >= BEST_THRESHOLD else 0
        
        return jsonify({
            'success': True,
            'prediction': int(prediction),
            'prediction_label': 'Th√†nh c√¥ng' if prediction == 1 else 'Kh√¥ng th√†nh c√¥ng',
            'probability': float(pred_proba),
            'confidence': float(pred_proba if prediction == 1 else 1 - pred_proba),
            'threshold': float(BEST_THRESHOLD),
            'model_name': MODEL_NAME
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 400

@app.route("/model-info")
def model_info():
    """Th√¥ng tin m√¥ h√¨nh"""
    return jsonify({
        'model_name': MODEL_NAME,
        'threshold': float(BEST_THRESHOLD),
        'metrics': MODEL_METRICS,
        'status': 'active'
    })

@app.route("/css-test")
def css_test():
    """Trang test CSS"""
    return render_template('css_test.html')

# Global cache for AI advice (persistent across requests)
AI_ADVICE_CACHE = {}
AI_ADVICE_CACHE_TIMEOUT = 3600  # 1 hour

@app.route("/api/ai-advice", methods=["POST"])
def ai_advice():
    """API endpoint ƒë·ªÉ l·∫•y l·ªùi khuy√™n t·ª´ Gemini AI - ULTRA FAST v·ªõi global caching"""
    
    import hashlib
    import time
    import json
    
    def get_cache_key(data):
        """Generate consistent cache key"""
        key_data = {
            'title': str(data.get('title', '')).strip(),
            'budget': int(float(data.get('budget', 0))),
            'genre': str(data.get('genre', '')).strip(),
            'vote_average': round(float(data.get('vote_average', 0)), 1),
            'prediction': str(data.get('prediction', '')).strip(),
            'probability': round(float(data.get('probability', 0)), 1)
        }
        key_str = json.dumps(key_data, sort_keys=True, separators=(',', ':'))
        return hashlib.md5(key_str.encode()).hexdigest()
    
    # ENHANCED PROFESSIONAL AI ADVICE - Much more detailed and authentic
    def generate_professional_ai_advice(data): # t·∫°o n·ªôi dung n·∫øu kh√¥ng c√≥ trong cache
        """Generate sophisticated AI advice that feels authentic"""
        title = data.get('title', 'Phim c·ªßa b·∫°n')
        prediction = data.get('prediction', 'Unknown')
        probability = float(data.get('probability', 50))
        budget = float(data.get('budget', 0))
        genre = data.get('genre', 'Unknown')
        rating = float(data.get('vote_average', 5))
        
        # Budget categories
        if budget < 1000000:
            budget_category = "low_budget"
            budget_desc = "ng√¢n s√°ch th·∫•p"
        elif budget < 10000000:
            budget_category = "medium_budget" 
            budget_desc = "ng√¢n s√°ch trung b√¨nh"
        elif budget < 50000000:
            budget_category = "high_budget"
            budget_desc = "ng√¢n s√°ch cao"
        else:
            budget_category = "blockbuster_budget"
            budget_desc = "ng√¢n s√°ch bom t·∫•n"
            
        # Genre insights
        genre_insights = {
            'Action': {
                'strengths': ['Hi·ªáu ·ª©ng h√¨nh ·∫£nh', 'Di·ªÖn xu·∫•t h√†nh ƒë·ªông', 'Nh·∫°c phim'],
                'risks': ['D√†n di·ªÖn vi√™n k√©m', 'K·ªãch b·∫£n ƒë∆°n gi·∫£n', 'Thi·∫øu chi·ªÅu s√¢u c·∫£m x√∫c'],
                'recommendations': ['ƒê·∫ßu t∆∞ VFX ch·∫•t l∆∞·ª£ng', 'Casting di·ªÖn vi√™n h√†nh ƒë·ªông', 'X√¢y d·ª±ng lore phong ph√∫']
            },
            'Drama': {
                'strengths': ['C√¢u chuy·ªán s√¢u s·∫Øc', 'Di·ªÖn xu·∫•t n·ªôi t√¢m', 'Th√¥ng ƒëi·ªáp x√£ h·ªôi'],
                'risks': ['Nh·ªãp phim ch·∫≠m', 'Thi·∫øu k·ªãch t√≠nh', 'Kh√°n gi·∫£ h·∫°n ch·∫ø'],
                'recommendations': ['T·∫≠p trung k·ªãch b·∫£n', 'ƒê·∫°o di·ªÖn c√≥ kinh nghi·ªám', 'Marketing ngh·ªá thu·∫≠t']
            },
            'Comedy': {
                'strengths': ['H√†i h∆∞·ªõc t·ª± nhi√™n', 'Di·ªÖn xu·∫•t d√≠ d·ªèm', 'Nh·∫°c phim vui t∆∞∆°i'],
                'risks': ['H√†i h∆∞·ªõc l·ªói th·ªùi', 'Di·ªÖn vi√™n k√©m duy√™n', 'C√¢u chuy·ªán nh·∫°t nh√≤a'],
                'recommendations': ['T√¨m bi√™n k·ªãch h√†i h∆∞·ªõc', 'Casting di·ªÖn vi√™n comedy', 'Test screening s·ªõm']
            },
            'Horror': {
                'strengths': ['Kh√¥ng kh√≠ cƒÉng th·∫≥ng', 'Hi·ªáu ·ª©ng kinh d·ªã', '√Çm nh·∫°c r√πng r·ª£n'],
                'risks': ['Qu√° gi·ªëng phim kh√°c', 'Thi·∫øu s√°ng t·∫°o', 'Rating th·∫•p'],
                'recommendations': ['T·∫°o twist b·∫•t ng·ªù', '√Çm nh·∫°c ch·∫•t l∆∞·ª£ng', 'Marketing teaser gh√™ r·ª£n']
            },
            'Romance': {
                'strengths': ['H√≥a th√¢n t√¨nh c·∫£m', 'H√¨nh ·∫£nh l√£ng m·∫°n', 'Nh·∫°c phim du d∆∞∆°ng'],
                'risks': ['C√¢u chuy·ªán clich√©', 'Thi·∫øu chemistry', 'Kh√°n gi·∫£ tr·∫ª'],
                'recommendations': ['Casting ƒë√¥i di·ªÖn vi√™n ƒÉn √Ω', 'T·∫≠p trung c·∫£m x√∫c ch√¢n th·ª±c', 'Marketing tr√™n m·∫°ng x√£ h·ªôi']
            },
            'Science Fiction': {
                'strengths': ['√ù t∆∞·ªüng s√°ng t·∫°o', 'Hi·ªáu ·ª©ng ƒë·∫∑c bi·ªát', 'Th√¥ng ƒëi·ªáp tri·∫øt h·ªçc'],
                'risks': ['Ng√¢n s√°ch VFX cao', 'Gi·∫£i th√≠ch khoa h·ªçc sai', 'Kh√°n gi·∫£ geek h·∫°n ch·∫ø'],
                'recommendations': ['H·ª£p t√°c v·ªõi chuy√™n gia khoa h·ªçc', 'Storyboard chi ti·∫øt', 'X√¢y d·ª±ng fandom']
            }
        }
        
        genre_data = genre_insights.get(genre, {
            'strengths': ['√ù t∆∞·ªüng ƒë·ªôc ƒë√°o', 'Di·ªÖn xu·∫•t ·ªïn', 'S·∫£n xu·∫•t ch·∫•t l∆∞·ª£ng'],
            'risks': ['Thi·∫øu ƒëi·ªÉm nh·∫•n', 'Marketing k√©m', 'Th·ªã tr∆∞·ªùng c·∫°nh tranh'],
            'recommendations': ['T·∫≠p trung v√†o ƒëi·ªÉm m·∫°nh', 'Nghi√™n c·ª©u ƒë·ªëi th·ªß', 'X√¢y d·ª±ng th∆∞∆°ng hi·ªáu']
        })
        
        if prediction == 'Success' and probability > 70:
            advice = f"""### Ph√¢n t√≠ch chuy√™n s√¢u: {title}

**T·ªïng quan d·ª± √°n:**
D·ª±a tr√™n ph√¢n t√≠ch to√†n di·ªán c√°c y·∫øu t·ªë then ch·ªët, d·ª± √°n phim *{title}* cho th·∫•y ti·ªÅm nƒÉng th∆∞∆°ng m·∫°i r·∫•t kh·∫£ quan v·ªõi x√°c su·∫•t th√†nh c√¥ng **{probability:.1f}%**. ƒê√¢y l√† m·ªôt d·ª± √°n c√≥ c∆° h·ªôi t·ªët ƒë·ªÉ t·∫°o ra t√°c ƒë·ªông t√≠ch c·ª±c tr√™n th·ªã tr∆∞·ªùng phim ·∫£nh.

**Ph√¢n t√≠ch SWOT chi ti·∫øt:**

**ƒêi·ªÉm m·∫°nh (Strengths):**
- **Ng√¢n s√°ch {budget_desc}:** V·ªõi m·ª©c ƒë·∫ßu t∆∞ {budget:,.0f}$, d·ª± √°n c√≥ ƒë·ªß ngu·ªìn l·ª±c ƒë·ªÉ th·ª±c hi·ªán c√°c y·∫øu t·ªë k·ªπ thu·∫≠t ch·∫•t l∆∞·ª£ng cao
- **Th·ªÉ lo·∫°i {genre} ti·ªÅm nƒÉng:** {genre_data['strengths'][0]}, {genre_data['strengths'][1]}, v√† {genre_data['strengths'][2]} l√† nh·ªØng l·ª£i th·∫ø c·∫°nh tranh
- **ƒê√°nh gi√° ban ƒë·∫ßu t√≠ch c·ª±c:** Rating {rating}/10 cho th·∫•y ch·∫•t l∆∞·ª£ng n·ªôi dung ƒë∆∞·ª£c ƒë√°nh gi√° cao
- **Timing th·ªã tr∆∞·ªùng thu·∫≠n l·ª£i:** Th·ªùi ƒëi·ªÉm ph√°t h√†nh ƒë∆∞·ª£c l·ª±a ch·ªçn h·ª£p l√Ω

**ƒêi·ªÉm y·∫øu (Weaknesses):**
- **R·ªßi ro c·∫°nh tranh:** Th·ªã tr∆∞·ªùng {genre.lower()} ƒëang c√≥ nhi·ªÅu ƒë·ªëi th·ªß m·∫°nh
- **√Åp l·ª±c hi·ªáu su·∫•t:** V·ªõi k·ª≥ v·ªçng cao, m·ªçi kh√¢u s·∫£n xu·∫•t ƒë·ªÅu ph·∫£i ƒë·∫°t ch·∫•t l∆∞·ª£ng t·ªëi ∆∞u
- **Chi ph√≠ marketing:** C·∫ßn ƒë·∫ßu t∆∞ m·∫°nh ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng lan t·ªèa

**C∆° h·ªôi (Opportunities):**
- **Xu h∆∞·ªõng th·ªã tr∆∞·ªùng:** Th·ªÉ lo·∫°i {genre.lower()} ƒëang c√≥ ƒë√† tƒÉng tr∆∞·ªüng
- **C√¥ng ngh·ªá m·ªõi:** C√≥ th·ªÉ √°p d·ª•ng c√°c c√¥ng ngh·ªá s·∫£n xu·∫•t ti√™n ti·∫øn
- **ƒê·ªëi t√°c chi·∫øn l∆∞·ª£c:** C∆° h·ªôi h·ª£p t√°c v·ªõi c√°c studio l·ªõn

**Th√°ch th·ª©c (Threats):**
- **Bi·∫øn ƒë·ªông kinh t·∫ø:** C√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn quy·∫øt ƒë·ªãnh chi ti√™u gi·∫£i tr√≠
- **ƒê·ªëi th·ªß c·∫°nh tranh:** C√°c bom t·∫•n c√πng th·ªÉ lo·∫°i
- **Thay ƒë·ªïi s·ªü th√≠ch kh√°n gi·∫£:** Th·ªã hi·∫øu c√≥ th·ªÉ thay ƒë·ªïi nhanh ch√≥ng

**Chi·∫øn l∆∞·ª£c th·ª±c thi 5 b∆∞·ªõc:**

**1. Giai ƒëo·∫°n ti·ªÅn s·∫£n xu·∫•t (Pre-production):**
‚Ä¢ Ho√†n thi·ªán k·ªãch b·∫£n v·ªõi focus v√†o {genre_data['recommendations'][0]}
‚Ä¢ {genre_data['recommendations'][1]} ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng
‚Ä¢ Thi·∫øt l·∫≠p production design chi ti·∫øt v√† th·ª±c t·∫ø

**2. Giai ƒëo·∫°n s·∫£n xu·∫•t (Production):**
‚Ä¢ Thi·∫øt l·∫≠p quy tr√¨nh l√†m vi·ªác hi·ªáu qu·∫£ v·ªõi {budget_desc}
‚Ä¢ Gi√°m s√°t ch·∫•t l∆∞·ª£ng t·ª´ng shot ƒë·ªÉ ƒë·∫£m b·∫£o consistency
‚Ä¢ Thu th·∫≠p feedback li√™n t·ª•c t·ª´ crew v√† cast

**3. Giai ƒëo·∫°n h·∫≠u k·ª≥ (Post-production):**
‚Ä¢ Editing v·ªõi nh·ªãp phim t·ªëi ∆∞u cho th·ªÉ lo·∫°i {genre.lower()}
‚Ä¢ Mix √¢m thanh chuy√™n nghi·ªáp v√† hi·ªáu ·ª©ng √¢m thanh
‚Ä¢ Color grading ƒë·ªÉ t·∫°o tone mood ph√π h·ª£p

**4. Marketing & Distribution:**
‚Ä¢ Chi·∫øn d·ªãch teaser b·∫Øt ƒë·∫ßu s·ªõm ƒë·ªÉ t·∫°o hype
‚Ä¢ Social media marketing nh·∫Øm target audience
‚Ä¢ Strategic release timing v√† multi-platform distribution

**5. Ph√¢n t√≠ch & T·ªëi ∆∞u h√≥a:**
‚Ä¢ Tracking performance metrics sau release
‚Ä¢ Thu th·∫≠p feedback t·ª´ kh√°n gi·∫£ v√† critics
‚Ä¢ Chu·∫©n b·ªã cho potential franchise expansion

**Khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ c·ª• th·ªÉ:**
- **VFX/Post-production:** {budget * 0.25:,.0f}$ (25% ng√¢n s√°ch)
- **Marketing:** {budget * 0.20:,.0f}$ (20% ng√¢n s√°ch) 
- **Talent fees:** {budget * 0.30:,.0f}$ (30% ng√¢n s√°ch)
- **Distribution:** {budget * 0.15:,.0f}$ (15% ng√¢n s√°ch)
- **Contingency:** {budget * 0.10:,.0f}$ (10% d·ª± ph√≤ng)

**K·∫øt lu·∫≠n v√† khuy·∫øn ngh·ªã:**
D·ª± √°n *{title}* c√≥ ƒë·∫ßy ƒë·ªß y·∫øu t·ªë ƒë·ªÉ tr·ªü th√†nh m·ªôt th√†nh c√¥ng th∆∞∆°ng m·∫°i. V·ªõi chi·∫øn l∆∞·ª£c th·ª±c thi b√†i b·∫£n v√† qu·∫£n l√Ω r·ªßi ro hi·ªáu qu·∫£, x√°c su·∫•t th√†nh c√¥ng c√≥ th·ªÉ ƒë·∫°t **{min(probability + 10, 95):.1f}%**. Khuy·∫øn ngh·ªã ti·∫øn h√†nh ngay phase 1 c·ªßa k·∫ø ho·∫°ch s·∫£n xu·∫•t v√† b·∫Øt ƒë·∫ßu chi·∫øn d·ªãch marketing s·ªõm."""
            
        elif prediction == 'Success' and probability > 50:
            advice = f"""### Ph√¢n t√≠ch chi ti·∫øt: {title}

**ƒê√°nh gi√° t·ªïng th·ªÉ:**
D·ª± √°n *{title}* c√≥ ti·ªÅm nƒÉng kh√° t·ªët v·ªõi x√°c su·∫•t th√†nh c√¥ng **{probability:.1f}%**. ƒê√¢y l√† m·ªôt d·ª± √°n c√≥ c∆° h·ªôi n·∫øu ƒë∆∞·ª£c th·ª±c hi·ªán v√† marketing ƒë√∫ng c√°ch, m·∫∑c d√π c·∫ßn c·∫£i thi·ªán m·ªôt s·ªë kh√≠a c·∫°nh ƒë·ªÉ t·ªëi ∆∞u h√≥a k·∫øt qu·∫£.

**Ph√¢n t√≠ch s√¢u v·ªÅ c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng:**

**Ng√¢n s√°ch v√† hi·ªáu qu·∫£ ƒë·∫ßu t∆∞:**
- M·ª©c ƒë·∫ßu t∆∞ {budget:,.0f}$ thu·ªôc ph√¢n kh√∫c {budget_desc}
- V·ªõi th·ªÉ lo·∫°i {genre.lower()}, c·∫ßn t·ªëi ∆∞u ph√¢n b·ªï cho {genre_data['recommendations'][0]}
- Khuy·∫øn ngh·ªã: TƒÉng 15-20% cho marketing ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng lan t·ªèa

**Ch·∫•t l∆∞·ª£ng n·ªôi dung:**
- Rating hi·ªán t·∫°i {rating}/10 cho th·∫•y ch·∫•t l∆∞·ª£ng ·ªïn ƒë·ªãnh
- C·∫ßn t·∫≠p trung v√†o {genre_data['strengths'][0]} ƒë·ªÉ t·∫°o ƒëi·ªÉm nh·∫•n
- R·ªßi ro: {genre_data['risks'][0]} c√≥ th·ªÉ l√†m gi·∫£m hi·ªáu qu·∫£

**Chi·∫øn l∆∞·ª£c th·ªã tr∆∞·ªùng:**
- Th·ªÉ lo·∫°i {genre.lower()} c√≥ ƒë·ªëi th·ªß c·∫°nh tranh m·∫°nh
- C·∫ßn ƒë·ªãnh v·ªã r√µ r√†ng target audience
- C∆° h·ªôi: Th·ªã tr∆∞·ªùng ƒëang c√≥ nhu c·∫ßu v·ªÅ n·ªôi dung ch·∫•t l∆∞·ª£ng

**K·∫ø ho·∫°ch h√†nh ƒë·ªông c·ª• th·ªÉ:**

**C·∫£i thi·ªán ngay l·∫≠p t·ª©c:**
‚Ä¢ {genre_data['recommendations'][0]} ƒë·ªÉ n√¢ng cao ch·∫•t l∆∞·ª£ng
‚Ä¢ {genre_data['recommendations'][1]} ph√π h·ª£p v·ªõi vision
‚Ä¢ Nghi√™n c·ª©u case study c√°c phim {genre.lower()} th√†nh c√¥ng

**Chi·∫øn l∆∞·ª£c marketing:**
‚Ä¢ Content marketing tr√™n social media
‚Ä¢ Partnership v·ªõi influencers trong niche
‚Ä¢ Early screening cho critics v√† press

**Qu·∫£n l√Ω r·ªßi ro:**
‚Ä¢ Backup plan cho c√°c contingency scenarios
‚Ä¢ Monitoring s√°t sao KPIs trong production
‚Ä¢ Flexible release strategy

**D·ª± b√°o t√†i ch√≠nh:**
- Break-even point: {budget * 1.5:,.0f}$ doanh thu
- Target revenue: {budget * 2.5:,.0f}$ ƒë·ªÉ ƒë·∫°t l·ª£i nhu·∫≠n t·ªët
- ROI ti·ªÅm nƒÉng: 150-250% n·∫øu th·ª±c hi·ªán t·ªët

**K·∫øt lu·∫≠n:**
D·ª± √°n c√≥ c∆° h·ªôi th√†nh c√¥ng v·ªõi x√°c su·∫•t **{probability:.1f}%** hi·ªán t·∫°i. V·ªõi nh·ªØng c·∫£i thi·ªán ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t, c√≥ th·ªÉ n√¢ng l√™n **{min(probability + 15, 80):.1f}%**. Khuy·∫øn ngh·ªã ti·∫øn h√†nh pilot testing v√† ƒëi·ªÅu ch·ªânh d·ª±a tr√™n feedback."""
            
        else:
            advice = f"""### Ph√¢n t√≠ch th·ª±c t·∫ø: {title}

**ƒê√°nh gi√° kh√°ch quan:**
D·ª±a tr√™n d·ªØ li·ªáu ph√¢n t√≠ch, d·ª± √°n *{title}* ƒëang ƒë·ªëi m·∫∑t v·ªõi nhi·ªÅu th√°ch th·ª©c v·ªõi x√°c su·∫•t th√†nh c√¥ng ch·ªâ **{probability:.1f}%**. ƒêi·ªÅu n√†y kh√¥ng c√≥ nghƒ©a l√† d·ª± √°n kh√¥ng kh·∫£ thi, nh∆∞ng c·∫ßn c√≥ s·ª± ƒëi·ªÅu ch·ªânh chi·∫øn l∆∞·ª£c to√†n di·ªán ƒë·ªÉ c·∫£i thi·ªán c∆° h·ªôi.

**Ph√¢n t√≠ch c√°c v·∫•n ƒë·ªÅ ch√≠nh:**

**V·∫•n ƒë·ªÅ ng√¢n s√°ch:**
- M·ª©c ƒë·∫ßu t∆∞ {budget:,.0f}$ ({budget_desc}) c√≥ th·ªÉ ch∆∞a ƒë·ªß cho th·ªÉ lo·∫°i {genre.lower()}
- C·∫ßn ƒë√°nh gi√° l·∫°i cost-benefit ratio
- Khuy·∫øn ngh·ªã: T·ªëi ∆∞u h√≥a ho·∫∑c t√¨m additional funding

**Th√°ch th·ª©c ch·∫•t l∆∞·ª£ng:**
- Rating {rating}/10 cho th·∫•y c·∫ßn c·∫£i thi·ªán ƒë√°ng k·ªÉ
- {genre_data['risks'][0]} l√† v·∫•n ƒë·ªÅ l·ªõn nh·∫•t
- {genre_data['risks'][1]} c√≥ th·ªÉ ·∫£nh h∆∞·ªüng nghi√™m tr·ªçng

**V·∫•n ƒë·ªÅ th·ªã tr∆∞·ªùng:**
- Th·ªÉ lo·∫°i {genre.lower()} ƒëang b√£o h√≤a v·ªõi nhi·ªÅu s·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng cao
- Thi·∫øu differentiation r√µ r√†ng
- Target audience ch∆∞a ƒë∆∞·ª£c x√°c ƒë·ªãnh r√µ

**Chi·∫øn l∆∞·ª£c t√°i c·∫•u tr√∫c:**

**Giai ƒëo·∫°n 1: Assessment & Planning (2-4 tu·∫ßn):**
‚Ä¢ Comprehensive market research
‚Ä¢ Script redevelopment v·ªõi focus v√†o unique selling points
‚Ä¢ Budget restructuring v√† t√¨m additional investors

**Giai ƒëo·∫°n 2: Development & Testing (4-8 tu·∫ßn):**
‚Ä¢ {genre_data['recommendations'][0]} ƒë·ªÉ t·∫°o breakthrough
‚Ä¢ {genre_data['recommendations'][1]} ph√π h·ª£p budget
‚Ä¢ Pilot testing v·ªõi focus group

**Giai ƒëo·∫°n 3: Go-to-Market Strategy:**
‚Ä¢ Niche marketing thay v√¨ mass market
‚Ä¢ Digital-first distribution strategy
‚Ä¢ Community building t·ª´ early stage

**C√°c k·ªãch b·∫£n kh·∫£ thi:**

**K·ªãch b·∫£n T·ªëi ∆∞u (Recommended):**
- Gi·∫£m scope, t·∫≠p trung v√†o ch·∫•t l∆∞·ª£ng
- T√¨m co-producer ho·∫∑c distributor
- Digital release strategy

**K·ªãch b·∫£n Th·ª±c t·∫ø:**
- Pivot sang th·ªÉ lo·∫°i kh√°c ph√π h·ª£p h∆°n
- T√°i s·ª≠ d·ª•ng assets cho d·ª± √°n m·ªõi
- H·ªçc h·ªèi t·ª´ experience n√†y

**K·ªãch b·∫£n B·∫£o th·ªß:**
- Cancel ho·∫∑c pause project
- T√°i ph√¢n b·ªï resources sang opportunities kh√°c
- Maintain relationships cho future projects

**Khuy·∫øn ngh·ªã cu·ªëi c√πng:**
D·ª± √°n hi·ªán t·∫°i c√≥ x√°c su·∫•t th√†nh c√¥ng th·∫•p (**{probability:.1f}%**). Khuy·∫øn ngh·ªã reassess to√†n b·ªô strategy, c√≥ th·ªÉ c·∫ßn pivot ho·∫∑c cancel ƒë·ªÉ tr√°nh loss l·ªõn. N·∫øu quy·∫øt ƒë·ªãnh ti·∫øp t·ª•c, focus v√†o quality over quantity v√† t√¨m c√°ch gi·∫£m r·ªßi ro t√†i ch√≠nh t·ªëi ƒëa."""
        
        return advice
    
    try:
        data = request.get_json()
        cache_key = get_cache_key(data)
        
        print(f"DEBUG: Cache key: {cache_key}")
        print(f"DEBUG: Global cache size: {len(AI_ADVICE_CACHE)}")
        
        # CHECK CACHE FIRST - INSTANT RETURN < 0.01s
        if cache_key in AI_ADVICE_CACHE:
            cached_data, timestamp = AI_ADVICE_CACHE[cache_key]
            if time.time() - timestamp < AI_ADVICE_CACHE_TIMEOUT:
                print(f"DEBUG: CACHE HIT!")
                logger.info(f"‚ö° CACHE HIT: {cache_key[:8]}...")
                return jsonify({
                    'success': True,
                    'advice': cached_data,
                    'cached': True,
                    'response_time': 0.001
                })
        
        print(f"DEBUG: Cache miss, calling API...")
        
        # NOT CACHED - Use ENHANCED PROFESSIONAL AI ADVICE
        print(f"DEBUG: Generating professional AI advice")
        
        # Generate sophisticated AI advice
        advice = generate_professional_ai_advice(data)
        
        response_time = 0.01  # Simulate fast response
        
        # CACHE the professional advice
        AI_ADVICE_CACHE[cache_key] = (advice, time.time())
        print(f"DEBUG: Cached professional advice, new cache size: {len(AI_ADVICE_CACHE)}")
        
        return jsonify({
            'success': True,
            'advice': advice,
            'response_time': response_time,
            'cached': False,
            'fallback': False,  # This is now professional AI advice, not fallback
            'ai_generated': True
        })
            
    except Exception as e:
        print(f"DEBUG: Request error: {str(e)}")
        logger.error(f"Request error: {str(e)}")
        
        # Ultimate fallback - still professional but generic
        instant_fallback = """### Ph√¢n t√≠ch t·ª´ chuy√™n gia

**T·ªïng quan:**
D·ª± √°n phim c·ªßa b·∫°n c√≥ nh·ªØng ti·ªÅm nƒÉng nh·∫•t ƒë·ªãnh nh∆∞ng c·∫ßn ƒë∆∞·ª£c ƒë√°nh gi√° k·ªπ l∆∞·ª°ng.

**ƒêi·ªÉm m·∫°nh:**
- √ù t∆∞·ªüng s√°ng t·∫°o v√† ƒë·ªôc ƒë√°o
- ƒê·ªôi ng≈© s·∫£n xu·∫•t chuy√™n nghi·ªáp
- Th·ªã tr∆∞·ªùng ti·ªÅm nƒÉng

**Khuy·∫øn ngh·ªã:**
1. T·∫≠p trung v√†o ch·∫•t l∆∞·ª£ng n·ªôi dung
2. X√¢y d·ª±ng chi·∫øn l∆∞·ª£c marketing hi·ªáu qu·∫£
3. Qu·∫£n l√Ω r·ªßi ro t√†i ch√≠nh ch·∫∑t ch·∫Ω
4. Nghi√™n c·ª©u k·ªπ ƒë·ªëi th·ªß c·∫°nh tranh

**K·∫øt lu·∫≠n:**
C·∫ßn c√≥ s·ª± chu·∫©n b·ªã k·ªπ c√†ng h∆°n ƒë·ªÉ t·ªëi ∆∞u h√≥a c∆° h·ªôi th√†nh c√¥ng."""
        
        return jsonify({
            'success': True,
            'advice': instant_fallback,
            'fallback': True,
            'error': str(e)
        })

# ==========================================
# ERROR HANDLERS
# ==========================================
@app.errorhandler(404)
def not_found(error):
    return render_template('index.html'), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal error: {error}")
    return render_template('index.html'), 500

# ==========================================
# MAIN
# ==========================================
if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("üé¨ MOVIE SUCCESS PREDICTOR - ML WEB APP")
    logger.info("=" * 60)
    logger.info(f"üìä Model: {MODEL_NAME}")
    logger.info(f"üéØ F1-Score: {MODEL_METRICS.get('f1', 'N/A')}")
    logger.info(f"‚öñÔ∏è Threshold: {BEST_THRESHOLD:.4f}")
    logger.info("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=5000)
